{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Exploratory Data Analysis (Using R)\"\nauthor: \"Venkatesh Mummidi\"\ndate: \"20 April 2017\"\noutput:\n  word_document: default\n  pdf_document: default\n  html_document: default\n---\nExploratory Data Analysis (EDA) can be broadly classified into  \n1.Graphical or Quantitative  \n2.Univariate or Bivariate  \n\nQuantitative methods include summary statistics while graphical methods include plots and charts. Univariate methods involve analysing one variable at a time while bivariate involves analysing two or more variables to examine their underlying relationships.  \n\n### Univariate  \n#### Univariate Quantitative\n##### Measures of central tendency\n  - Mean  \n  - Median  \n  - Mode  \n  \n##### Measures of dispersion\n  - Min  \n  - Max  \n  - Range  \n  - Quartiles  \n  - Variance  \n  - Standard deviation  \n  \n#### Univariate Graphical\n  - Histogram  \n  - Boxplots  \n  - Barplots  \n\n### Bivariate\n#### Bivariate Quantitative\n  - Crosstabs\n  - Covariance\n  - Correlation \n\n#### Bivariate Graphical\n  - Scatterplot  \n  - Boxplot\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n```{r,message=FALSE,warning=FALSE}\nlibrary(Hmisc)\nlibrary(ggplot2)\nlibrary(mice)\nlibrary(missForest)\nlibrary(TSA)\n```\n\nWe are using inbuilt dataset 'mpg' for our analysis\n\n```{r}\ndata(\"mpg\")\nhead(mpg) #first 6 rows of the dataset\ndim(mpg)   #no of rows and coloumns\n\nstr(mpg) # structure of the dataset\nclass(mpg) #type of data\n\nsummary(mpg) \nnames(mpg) #variable names\n```\n\nThe describe() function which is part of the Hmisc package displays the following additional statistics:\n\n  Number of rows  \n  Standard deviation  \n  Trimmed mean  \n  Mean absolute deviation  \n  Skewness  \n  Kurtosis  \n  Standard error  \n  \n```{r}\ndescribe(mpg)\n\n```\n\n    \n### Univariate Plots\n\n#### Histograms\n```{r}\nggplot(mpg,aes(cty))+geom_histogram(bins = 30,fill='red',colour='black')+geom_vline(aes(xintercept = mean(cty)),linetype='dashed',color='blue',size=1)\n\nggplot(mpg,aes(hwy))+geom_histogram(bins = 30,fill='red',colour='black')+geom_vline(aes(xintercept = mean(hwy)),linetype='dashed',color='blue',size=1)\n\nggplot(mpg,aes(displ))+geom_histogram(bins = 30,fill='red',colour='black')+geom_vline(aes(xintercept = mean(displ)),linetype='dashed',color='blue',size=1)\n\n\n```\n\n```{r}\nggplot(mpg,aes(1,cty))+geom_boxplot(outlier.colour = 'red')\nggplot(mpg,aes(1,hwy))+geom_boxplot(outlier.colour = 'red')\nggplot(mpg,aes(1,displ))+geom_boxplot(outlier.colour = 'red')\n\n```\n\n###Bivariate analysis\n#### cross tabs\n```{r}\ntable(mpg$manufacturer,mpg$year)\ntable(mpg$manufacturer,mpg$class)\ntable(mpg$manufacturer,mpg$cyl)\n\n```\n#### correlation\n```{r}\ncor(mpg$hwy,mpg$cty)\n```\n\n#### Scatterplot\n```{r}\n\nggplot(mpg,aes(hwy,displ))+geom_point()\nggplot(mpg,aes(hwy,cty))+geom_point()\nggplot(mpg,aes(hwy,cty))+geom_point(aes(color=factor(class)))\n\n```\n\n\n#### Boxplot\n```{r}\nggplot(mpg, aes(class, hwy))+geom_boxplot(outlier.colour = 'red')\nggplot(mpg, aes(class, cty))+geom_boxplot(outlier.colour = 'red')\nggplot(mpg, aes(class, hwy))+geom_boxplot(aes(color=drv))\n```\n\n### Outlier detection & imputation\n\nFrom boxplot we can find which variables are having outliers. Upon identifying the variables, we need to get outliers values\n\n```{r}\nboxplot.stats(mpg$cty)\n```\n\nstats - Five point summary of boxplot ||\nn - No of observations ||\nconf - Confidence interval of variable ||\nout - outliers detected.\n\n```{r}\nboxplot.stats(mpg$cty)$out\nout.indx <- which(mpg$cty %in% (boxplot.stats(mpg$cty)$out)) #gives the index of outliers\nout.indx\n\n#Replacing outliers with the max value in boxplot\nmax.val <- boxplot.stats(mpg$cty)$stats[5]\nmpg$cty[out.indx] <- max.val\n```\nOutliers can also be imputed by mean or median.\n\n### Missing value imputation\n```{r}\ntable(is.na(mpg))\n```\nThere are no missing values. So manually add some NAs\n```{r}\n#seed missing values ( 10% )\nmpg.mis <- prodNA(mpg, noNA = 0.1)\ntable(is.na(mpg.mis))\n```\n\nMICE (Multivariate Imputation via Chained Equations) is one of the commonly used package by R users.\nThe methods used by this package are:\n\n  1.PMM (Predictive Mean Matching)  - For numeric variables  \n  2.logreg(Logistic Regression) - For Binary Variables( with 2 levels)  \n  3.polyreg(Bayesian polytomous regression) - For Factor Variables (>= 2 levels)  \n  4.Proportional odds model (ordered, >= 2 levels)  \n  \n```{r}\n# considering numerical values\nmpg.mis.num <- subset(mpg.mis, select = c(cty,hwy,displ))\nimputed_Data <- mice(mpg.mis.num,m=5,maxit = 500, method = 'pmm', seed = 500,printFlag = F)\nsummary(imputed_Data)\n\n```\n\nHere is an explanation of the parameters used:\n\n  1.m  - Refers to 5 imputed data sets  \n  2.maxit - Refers to no. of iterations taken to impute missing values  \n  3.method - Refers to method used in imputation. we used predictive mean matching.  \n\n```{r,results='hide'}\ncomplete(imputed_Data,3) #get complete data ( 3rd out of 5)\n\n```\n\n```{r}\nimputed_Data$imp$cty  #check imputed values\n```\nVarious other packages like Hmisc,rfImpute can also be used to impute missing data.\n\n  \n  \n### Timeseries\nConsidering inbuild dataset 'Airpassengers' for analysis.  \n\nEDA for timeseries can include  \n\n-Plotting the raw data using line charts, histograms, bi-histograms, probability plots, lag plots, etc.  \n-Plotting simple statistics such as mean plots, standard deviation plots, box plots, and main effects plots of the raw data.  \n\n\n```{r}\ndata(\"AirPassengers\")\ncycle(AirPassengers)\n```\nIndicates that this is a monthly timeseries data. This can also be determined by frequency command.\n```{r}\nfrequency(AirPassengers)\n```\n```{r}\nmean(AirPassengers)\nrange(AirPassengers) #returns min and max values\nhist(AirPassengers)\nplot(AirPassengers)\n```\n  \nWe can see that data is not stationary as both mean and variance are changing.  \n```{r}\nplot(aggregate(AirPassengers),ylab=\"Mean of each month\") #plotting mean of each month\nboxplot(AirPassengers~cycle(AirPassengers)) #Boxplot of data across each month\n\n```\n  \n  As the data is not stationary, we need to remove stationary. Differentiate the data to detrend the data. Also we need to remove unequal variances. We do this using log of the series  \n\n```{r}\nplot(diff(log(AirPassengers))) #Now we can observe the data is stationary.\n```\n\n#### Determine whether the timeseries is AR or MA model\nThis can be known from ACF(Auto correlation function) and PACF (Partial Auto correlation function)\n\nACF is a plot of total correlation between different lag functions. For instance, in Air passengers problem, the passengers at time point t is x(t). We are interested in the correlation of x(t) with x(t-1) , x(t-2) and so on.   \n  \nIn a moving average series of lag n, we will not get any correlation between x(t) and x(t â€“ n -1) . Hence, the total correlation chart cuts off at nth lag. So it becomes simple to find the lag for a MA series. For an AR series this correlation will gradually go down without any cut off value.   \n\nThe partial correlation of each lag, it will cut off after the degree of AR series. For instance,if we have a AR(1) series,  if we exclude the effect of 1st lag (x (t-1) ), our 2nd lag (x (t-2) ) is independent of x(t). Hence, the partial correlation function (PACF) will drop sharply after the 1st lag. \n\n\n```{r}\nacf(diff(log(AirPassengers)))\npacf(diff(log(AirPassengers)))\n```\n\n\nThere are three parameters for passing to the arima model -> (p,d,q)  \np - Order of AR  \nd - Order of differentiation  \nq - order of MA  \n\nClearly, ACF plot cuts off after the first lag. Hence, we understood that value of p should be 0 as the ACF is the curve getting a cut off. So value of q should be 1. As we are differentiating once, value of d is 1.  \n  \nFinally this is a MA1 timeseries model.  \n\n```{r}\n# Fitting an arima model for timeseries data\n(fit <- arima(log(AirPassengers), c(0, 1, 1),seasonal = list(order = c(0, 1, 1), period = 12)))\n\n```\n\n#### What if there are outliers in timeseries data?\nAdding a potential outlier to our data.  \n```{r}\nlibrary(TSA)\nap.out <- AirPassengers\nap.out[89] <- 1100  #Adding a value of 1000 at index 89.\nplot(ap.out)\nfit.out <- arima(log(ap.out),c(0,1,1),\n             seasonal = list(order=c(0,1,1),period=12))\ndetectAO(fit.out)\ndetectIO(fit.out)\n```\n  \ndetectAO detects additive outliers. Additive outliers affects only single observation.  \ndetectIO detects innovative outliers. This effect continues in a lagged fashion with all future observations. We can see that the outlier we added is Innovative outlier and is detected by detectIO function.  \n  \nind represents time series index of outlier.\n\n\n\n\n\n\n\n\n\n",
    "created" : 1493185321825.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1152024707",
    "id" : "B85E6A04",
    "lastKnownWriteTime" : 1493293471,
    "last_content_update" : 1493358456658,
    "path" : "~/EDA.rmd",
    "project_path" : null,
    "properties" : {
        "last_setup_crc32" : ""
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}